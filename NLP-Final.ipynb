{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucaskenjis\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Imports para NLP\n",
    "#from nltk import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remover review duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.review.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remover colunas null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df.review.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método para limpeza de texto aplicando:\n",
    "    - replace para um caractere específico\n",
    "    - limpeza de linguagem html usando BeautifulSoup\n",
    "    - regexp_tokenize para transformar textos em tokens, e coletar apenas palavras através do regex [\\w']+. Ignorando acentos.\n",
    "    - .lower() para deixar as palavras minusculas\n",
    "    - stopwords para remover palavras que não agregam informações\n",
    "    - stemming para extrair o radical das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "ps = PorterStemmer()\n",
    "eng_stpw = set(stopwords.words('english'))\n",
    "\n",
    "def padronizardados(text):\n",
    "    t = text.replace('\\'','')\n",
    "    soup = BeautifulSoup(t, \"html.parser\")\n",
    "    text = regexp_tokenize(soup.get_text().lower(),\"[\\w']+\")\n",
    "    temp = []\n",
    "    for t in text:\n",
    "        if t not in eng_stpw:\n",
    "            temp.append(ps.stem(t))\n",
    "    new_text = (' '.join(temp))\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Texto antes do método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taut and organically gripping, Edward Dmytryk\\'s Crossfire is a distinctive suspense thriller, an unlikely \"message\" movie using the look and devices of the noir cycle.<br /><br />Bivouacked in Washington, DC, a company of soldiers cope with their restlessness by hanging out in bars. Three of them end up at a stranger\\'s apartment where Robert Ryan, drunk and belligerent, beats their host (Sam Levene) to death because he happens to be Jewish. Police detective Robert Young investigates with the help of Robert Mitchum, who\\'s assigned to Ryan\\'s outfit. Suspicion falls on the second of the three (George Cooper), who has vanished. Ryan slays the third buddy (Steve Brodie) to insure his silence before Young closes in.<br /><br />Abetted by a superior script by John Paxton, Dmytryk draws precise performances from his three starring Bobs. Ryan, naturally, does his prototypical Angry White Male (and to the hilt), while Mitchum underplays with his characteristic alert nonchalance (his role, however, is not central); Young may never have been better. Gloria Grahame gives her first fully-fledged rendition of the smart-mouthed, vulnerable tramp, and, as a sad sack who\\'s leeched into her life, Paul Kelly haunts us in a small, peripheral role that he makes memorable.<br /><br />The politically engaged Dmytryk perhaps inevitably succumbs to sermonizing, but it\\'s pretty much confined to Young\\'s reminiscence of how his Irish grandfather died at the hands of bigots a century earlier (thus, incidentally, stretching chronology to the limit). At least there\\'s no attempt to render an explanation, however glib, of why Ryan hates Jews (and hillbillies and...).<br /><br />Curiously, Crossfire survives even the major change wrought upon it -- the novel it\\'s based on (Richard Brooks\\' The Brick Foxhole) dealt with a gay-bashing murder. But homosexuality in 1947 was still Beyond The Pale. News of the Holocaust had, however, begun to emerge from the ashes of Europe, so Hollywood felt emboldened to register its protest against anti-Semitism (the studios always quaked at the prospect of offending any potential ticket buyer).<br /><br />But while the change from homophobia to anti-Semitism works in general, the specifics don\\'t fit so smoothly. The victim\\'s chatting up a lonesome, drunk young soldier then inviting him back home looks odd, even though (or especially since) there\\'s a girlfriend in tow. It raises the question whether this scenario was retained inadvertently or left in as a discreet tip-off to the original engine generating Ryan\\'s murderous rage.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicando método de limpeza aos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(padronizardados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Texto depois do método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taut organ grip edward dmytryk crossfir distinct suspens thriller unlik messag movi use look devic noir cycl bivouack washington dc compani soldier cope restless hang bar three end stranger apart robert ryan drunk belliger beat host sam leven death happen jewish polic detect robert young investig help robert mitchum who assign ryan outfit suspicion fall second three georg cooper vanish ryan slay third buddi steve brodi insur silenc young close abet superior script john paxton dmytryk draw precis perform three star bob ryan natur prototyp angri white male hilt mitchum underplay characterist alert nonchal role howev central young may never better gloria graham give first fulli fledg rendit smart mouth vulner tramp sad sack who leech life paul kelli haunt us small peripher role make memor polit engag dmytryk perhap inevit succumb sermon pretti much confin young reminisc irish grandfath die hand bigot centuri earlier thu incident stretch chronolog limit least there attempt render explan howev glib ryan hate jew hillbilli curious crossfir surviv even major chang wrought upon novel base richard brook brick foxhol dealt gay bash murder homosexu 1947 still beyond pale news holocaust howev begun emerg ash europ hollywood felt embolden regist protest anti semit studio alway quak prospect offend potenti ticket buyer chang homophobia anti semit work gener specif dont fit smoothli victim chat lonesom drunk young soldier invit back home look odd even though especi sinc there girlfriend tow rais question whether scenario retain inadvert left discreet tip origin engin gener ryan murder rage'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformar sentiments em 0 e 1 (Label encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "tag = le.fit_transform(df.sentiment)\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dados\n",
    "    - Optei por separar os dados em treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "X_train, X_test, y_train, y_test  = train_test_split(df.review, df.sentiment, test_size=0.2, random_state=1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words utilizando ngram no range(1,2) para procurar palavras que se complementam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=20000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "selected_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection + L1 e Regressao logistica\n",
    "    - Seleção de features utilizando um loop para testar alguns pesos para o paramentro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucaskenjis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.25 minutos \n",
      "\n",
      "6.08 minutos \n",
      "\n",
      "10.36 minutos \n",
      "\n",
      "16.37 minutos \n",
      "\n",
      "22.48 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cs=[.01,.1,1,10,100]\n",
    "#\n",
    "summary=[]\n",
    "\n",
    "for c in cs:\n",
    "    \n",
    "    #seleção de atributos\n",
    "    logreg = LogisticRegression(solver='saga', penalty='l1',C=c, max_iter=100).fit(X_train, y_train)\n",
    "    select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "    X_train_sel=select_features.transform(X_train)\n",
    "    X_test_sel=select_features.transform(X_test)\n",
    "    X_val_sel=select_features.transform(X_val)\n",
    "\n",
    "    #fittando o modelo\n",
    "    model_cv = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "    #avaliando acurácia\n",
    "    model_cv_score = model_cv.score(X_val_sel, y_val)\n",
    "    \n",
    "    #resumo da validação\n",
    "    summary.append((c,np.shape(X_train_sel)[1],model_cv_score))\n",
    "    \n",
    "    print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 215, 0.8550110909457552),\n",
       " (0.1, 1916, 0.8933252671909659),\n",
       " (1, 14999, 0.9005847953216374),\n",
       " (10, 19864, 0.8995765275257108),\n",
       " (100, 19996, 0.8995765275257108)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 Features=215 Acc=0.8550\n",
      "C=0.10 Features=1916 Acc=0.8933\n",
      "C=1.00 Features=14999 Acc=0.9006\n",
      "C=10.00 Features=19864 Acc=0.8996\n",
      "C=100.00 Features=19996 Acc=0.8996\n"
     ]
    }
   ],
   "source": [
    "for i in summary:\n",
    "  print(\"C=%.2f Features=%d Acc=%3.4f\" %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do modelo com o melhor peso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucaskenjis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.41 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='saga', penalty='l1',C=1, max_iter=100).fit(X_train, y_train)\n",
    "select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "X_train_sel=select_features.transform(X_train)\n",
    "X_test_sel=select_features.transform(X_test)\n",
    "X_val_sel=select_features.transform(X_val)\n",
    "\n",
    "model_cv = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "lg_score = model_cv.score(X_val_sel, y_val)\n",
    "    \n",
    "summary.append((c,np.shape(X_train_sel)[1],lg_score))\n",
    "    \n",
    "print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo criado com as variáveis teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia na base de teste=0.888 \n",
      "\n",
      "[[2187  245]\n",
      " [ 309 2217]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia na base de teste=%3.3f \\n\" % model_cv.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = model_cv.predict(X_test_sel)\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dados\n",
    "    - Optei por separar os dados em treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "X_train, X_test, y_train, y_test  = train_test_split(df.review, df.sentiment, test_size=0.2, random_state=1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF utilizando ngram no range(1,2) para procurar palavras que se complementam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),max_features=20000)\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_val = tfidf.transform(X_val)\n",
    "X_test = tfidf.transform(X_test)\n",
    "selected_features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection + L1 e Regressao logistica\n",
    "    - Seleção de features utilizando um loop para testar alguns pesos para o paramentro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.92 minutos \n",
      "\n",
      "30.97 minutos \n",
      "\n",
      "31.39 minutos \n",
      "\n",
      "33.61 minutos \n",
      "\n",
      "38.34 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cs=[.01,.1,1,10,100]\n",
    "#\n",
    "summary=[]\n",
    "\n",
    "for c in cs:\n",
    "    \n",
    "    #seleção de atributos\n",
    "    logreg = LogisticRegression(solver='saga', penalty='l1',C=c, max_iter=100).fit(X_train, y_train)\n",
    "    select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "    X_train_sel=select_features.transform(X_train)\n",
    "    X_test_sel=select_features.transform(X_test)\n",
    "    X_val_sel=select_features.transform(X_val)\n",
    "\n",
    "    #fittando o modelo\n",
    "    model_tfidf = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "    #avaliando acurácia\n",
    "    model_tfidf_score = model_tfidf.score(X_val_sel, y_val)\n",
    "    \n",
    "    #resumo da validação\n",
    "    summary.append((c,np.shape(X_train_sel)[1],model_tfidf_score))\n",
    "    \n",
    "    print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 Features=2 Acc=0.6116\n",
      "C=0.10 Features=139 Acc=0.8457\n",
      "C=1.00 Features=1512 Acc=0.8883\n",
      "C=10.00 Features=9833 Acc=0.9000\n",
      "C=100.00 Features=18425 Acc=0.9008\n"
     ]
    }
   ],
   "source": [
    "for i in summary:\n",
    "  print(\"C=%.2f Features=%d Acc=%3.4f\" %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do modelo com o melhor peso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.67 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='saga', penalty='l1',C=100, max_iter=100).fit(X_train, y_train)\n",
    "select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "X_train_sel=select_features.transform(X_train)\n",
    "X_test_sel=select_features.transform(X_test)\n",
    "X_val_sel=select_features.transform(X_val)\n",
    "\n",
    "model_tfidf = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "model_tfidf_score = model_tfidf.score(X_val_sel, y_val)\n",
    "    \n",
    "summary.append((c,np.shape(X_train_sel)[1],model_tfidf_score))\n",
    "    \n",
    "print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo criado com as variáveis teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia na base de teste=0.896 \n",
      "\n",
      "[[2198  218]\n",
      " [ 298 2244]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia na base de teste=%3.3f \\n\" % model_tfidf.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = model_tfidf.predict(X_test_sel)\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dados\n",
    "    - Optei por separar os dados em treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformando os dados no formato Texto, tag com TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_tagged = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "#val_tagged = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_val)]\n",
    "#test_tagged = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['review'].split(' '), tags=[r.sentiment]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['review'].split(' '), tags=[r.sentiment]), axis=1)\n",
    "val_tagged = val.apply(\n",
    "    lambda r: TaggedDocument(words=r['review'].split(' '), tags=[r.sentiment]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['one', 'review', 'mention', 'watch', '1', 'oz', 'episod', 'youll', 'hook', 'right', 'exactli', 'happen', 'first', 'thing', 'struck', 'oz', 'brutal', 'unflinch', 'scene', 'violenc', 'set', 'right', 'word', 'go', 'trust', 'show', 'faint', 'heart', 'timid', 'show', 'pull', 'punch', 'regard', 'drug', 'sex', 'violenc', 'hardcor', 'classic', 'use', 'word', 'call', 'oz', 'nicknam', 'given', 'oswald', 'maximum', 'secur', 'state', 'penitentari', 'focus', 'mainli', 'emerald', 'citi', 'experiment', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inward', 'privaci', 'high', 'agenda', 'em', 'citi', 'home', 'mani', 'aryan', 'muslim', 'gangsta', 'latino', 'christian', 'italian', 'irish', 'scuffl', 'death', 'stare', 'dodgi', 'deal', 'shadi', 'agreement', 'never', 'far', 'away', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'goe', 'show', 'wouldnt', 'dare', 'forget', 'pretti', 'pictur', 'paint', 'mainstream', 'audienc', 'forget', 'charm', 'forget', 'romanc', 'oz', 'doesnt', 'mess', 'around', 'first', 'episod', 'ever', 'saw', 'struck', 'nasti', 'surreal', 'couldnt', 'say', 'readi', 'watch', 'develop', 'tast', 'oz', 'got', 'accustom', 'high', 'level', 'graphic', 'violenc', 'violenc', 'injustic', 'crook', 'guard', 'wholl', 'sold', 'nickel', 'inmat', 'wholl', 'kill', 'order', 'get', 'away', 'well', 'manner', 'middl', 'class', 'inmat', 'turn', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experi', 'watch', 'oz', 'may', 'becom', 'comfort', 'uncomfort', 'view', 'that', 'get', 'touch', 'darker', 'side'], tags=['positive'])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o modelo Doc2Vec com o vocabulario de train_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_d2v = Doc2Vec(train_tagged,min_count=3,\n",
    "                     window=5,\n",
    "                     vector_size=20, \n",
    "                     negative=5,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_d2v.build_vocab([x for x in (train_tagged.values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando o modelo\n",
    "The parameters:\n",
    "\n",
    "- dados de treino ( text,tag)\n",
    "- total_examples = int - Count of sentences;\n",
    "- epochs = int - Number of iterations (epochs) over the corpus - [10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 421.79 mins\n"
     ]
    }
   ],
   "source": [
    "model_d2v.train(train_tagged, total_examples=model_d2v.corpus_count,epochs=30)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time.time() - start_time) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39665,), (4958,), (4959,))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.shape,test_tagged.shape,val_tagged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    model.random.seed(1)\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_d2v, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_d2v, test_tagged)\n",
    "y_val,X_val = vec_for_learning(model_d2v, val_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "normalized_train = preprocessing.normalize(X_train)\n",
    "normalized_test = preprocessing.normalize(X_test)\n",
    "normalized_val = preprocessing.normalize(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39665, 20)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection + L1 e Regressao logistica\n",
    "    - Seleção de features utilizando um loop para testar alguns pesos para o paramentro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426.23 minutos \n",
      "\n",
      "426.25 minutos \n",
      "\n",
      "426.27 minutos \n",
      "\n",
      "426.28 minutos \n",
      "\n",
      "426.3 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cs=[.01,.1,1,10,100]\n",
    "#\n",
    "summary=[]\n",
    "\n",
    "\n",
    "for c in cs:\n",
    "    \n",
    "    #seleção de atributos\n",
    "    logreg = LogisticRegression(solver='saga', penalty='l1',C=c, max_iter=500).fit(normalized_train, y_train)\n",
    "    select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "    X_train_sel=select_features.transform(normalized_train)\n",
    "    X_test_sel=select_features.transform(normalized_test)\n",
    "    X_val_sel=select_features.transform(normalized_val)\n",
    "\n",
    "    #fittando o modelo\n",
    "    model_d2v = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "    #avaliando acurácia\n",
    "    model_d2v_score = model_d2v.score(X_val_sel, y_val)\n",
    "    \n",
    "    #resumo da validação\n",
    "    summary.append((c,np.shape(X_train_sel)[1],model_d2v_score))\n",
    "    \n",
    "    print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 Features=18 Acc=0.8389\n",
      "C=0.10 Features=20 Acc=0.8405\n",
      "C=1.00 Features=20 Acc=0.8405\n",
      "C=10.00 Features=20 Acc=0.8405\n",
      "C=100.00 Features=20 Acc=0.8405\n"
     ]
    }
   ],
   "source": [
    "for i in summary:\n",
    "  print(\"C=%.2f Features=%d Acc=%3.4f\" %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do modelo com o melhor peso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429.06 minutos \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='saga', penalty='l1',C=.1, max_iter=100).fit(normalized_train, y_train)\n",
    "select_features = SelectFromModel(logreg, prefit=True)\n",
    "    \n",
    "X_train_sel=select_features.transform(normalized_train)\n",
    "X_test_sel=select_features.transform(normalized_test)\n",
    "X_val_sel=select_features.transform(normalized_val)\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter=100).fit(X_train_sel, y_train)\n",
    "    \n",
    "logregScore = model.score(X_val_sel, y_val)\n",
    "    \n",
    "summary.append((c,np.shape(X_train_sel)[1],logregScore))\n",
    "    \n",
    "print(round((time.time() - start_time)/60,2),\"minutos \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo criado com as variáveis teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia na base de teste=0.834 \n",
      "\n",
      "[[2061  387]\n",
      " [ 435 2075]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia na base de teste=%3.3f \\n\" % model.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test_sel)\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
